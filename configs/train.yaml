training:
  batch_size: 32
  validation_ratio: 0.2
  num_epochs: 30
  additional_train: True
  additional_epochs: 10
  learning_rate: 0.00005109960074261034
  n_splits: 3

  metric: "accuracy"
  criterion: "CrossEntropyLoss"

  optimizer: "Adam"
  weight_decay: 0.0001

  lr_scheduler:
    name: "ReduceLROnPlateau"
    factor: 0.1
    patience: 3
    min_lr: 1e-6
    monitor: 'metric'

  early_stopping:
    patience: 5
    min_delta: 0.001
    evidence: 'loss'
    monitor: 'metric'

model:
  name: "deit_base_patch16_224"
  pretrained: True
  num_classes: 1000
